{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce4d872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-24 19:48:43,490 loading file C:\\Users\\mohit\\.flair\\models\\ner-english-ontonotes-fast\\0d55dd3b912da9cf26e003035a0c269a0e9ab222f0be1e48a3bbba3a58c0fed0.c9907cd5fde3ce84b71a4172e7ca03841cd81ab71d13eb68aa08b259f57c00b6\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import torch\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/ner-english-ontonotes-fast\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b6db617",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Rons 1-on-1\n",
    "\n",
    "Amuthan Leaving: \n",
    "One of the things he was working on was a Python job to sync the on Prem secret server secrets with Azure Key Vault that's been kind of on hold, but it's based off of our Python job so. He's gonna hand over whatever information he's gathered on that on the requirements. Sure, there's. Yeah, there's no no movement on it yet, but just you. You could be the repository of that information until we get a replacement for a move on. Sure, yeah. I think you're familiar with it. So yeah, I will do that and I'm familiar with that job. So it connects to the secret server, gets a JSON load payload back, and then we parse that JSON to connect our datasets. In addition replacement, we will just use another API from the keyboard and the kind of. To maintain a sink or somehow you know that, like with some metadata information, that everything is In Sync with a daily cadence or whatever like and number of minutes cadence. So I think that's what they settled on. Obviously you'd need an on demand option if you're sticking with daily. Yes, yes, but. I don't think he got much further than than just describing it the way you did. Oh, I see. OK, so that that sounds reasonable. I will set something up so that he can transfer the repository of information to me. I'll capture it somewhere and whenever we have the replacement, I can do the transition. Great, thank you, MJ thank you.\n",
    "\n",
    "\n",
    "\n",
    "I confirmed it in one of the meetings and Reese confirmed that he didn't give any details when it's the last day and whatnot where it's going to be a big loss for specially the Azure project, especially from a data governance and all the other things that are brought to the table. Yeah yeah, and he was really really good at working with the business and and gathering requirements. Just. His core technology is snowflake and boy that sure would have been handy when we get that far in the Azure project, but. \n",
    "\n",
    "He he was afraid he was getting rusty here. So plus this other place, right? He's better. So yeah, I think on that's there with a lot of people, even sometimes the year and I used to talk in private and he also mentioned some frustration that we are not moving that fast. 'cause the business is not aligned and new technologies and their difference of opinions among people and everything gets done in when everybody votes. Yes one person says. No, you know it gets vetoed. Yep, Yep, everybody has to be tough. Anyway, I I just wanted to let you know about that.  No problem. Anything else on Amazon's plate. Ron that I need to take care about. \n",
    "\n",
    "Margie - Extended Logging\n",
    "\n",
    "Well, I was talking to Margie and she said she had tried to get the extended logging from talent data catalog and didn't really see much difference. But I I told her, you know, just go ahead and take that log. Go ahead and create the ticket. \n",
    "\n",
    "Sure would count yes. And if they want more, they'll tell you what they want exactly and how to get it. You know they will tell us? Yeah yes. So so she's gonna take a stab at that if she gets stuck. Where I can help her, but I think she can handle creating a ticket. Sure, that sounds good and she's also been working with it to. There's kind of a a mismatch if we pull our database schemas from ER studio and from the live database. Stitching the talent data catalog or the the data integration stuff. Yes it will stitch well to the database because it the the database names match up. Schema names match up. Yeah, so the ER studio, we've gotten really match up. I've been playing with pushing all of the the metadata that's documented in ER studio into extended properties in the database, and the experiment was does data catalog see those extended properties and so far the answer is yes, so she may be about to make a huge step forward and get all the metadata into data catalog. That way I see OK. So just to get a better handle of what you said and I'll try to rephrase. \n",
    "\n",
    "So the snapshot on the actual data basis. It doesn't tie out exactly 1 to one with the ER studio, and what margin is working once if we put catalog in the middle and we stitch everything from the databases, which will be like 1 to one stitching from a catalog perspective and on the other hand, if ER studio also we are able to switch to catalog then we get all the. Data at one place and it's going to be the complete metadata that we need for catalog. Yes, yes, and there's a couple of additional capabilities that there are optional, but you can. You can sample data from the database and you know keep 10 records or 100 records so people can see what your data looks like. \n",
    "\n",
    "\n",
    "That that's always one of the first things you do when you're learning a new data set. Yes, and it will profile the data so it will take a very very large sample and give you a profile. OK, which are two things that Kyle McKay is asked for. With the health claims so right I see I see. So he wants profile and he wants some kind of a display just like other tools. Do you know, for example, any tool would give you a display off the first few records, how they look like and also it has masking I believe so we can mask certain fields. So based on who's using the the the tool? Yep, Yep, Yep, so that. That's all good. \n",
    "\n",
    "\n",
    "And then we've got a call with Cornelius from Talent scheduled next week. Yes, and I'm gonna talk to him about getting a A. Data catalog consultant in sometime you know Michelle's financial data warehouse is going to be the first one that's complete enough that it it's ready for catalog and Michelle is very interested in seeing the product right? So that's why I've been working on those SQL statements to tie the stuff from studio into catalog, right?\n",
    "\n",
    " And then then we can automate that stuff and get an expert in to show us how to use catalog 'cause it's changed a bit since we took training. Yes, that'll be helpful, and yeah, that'll be helpful in many ways around. \n",
    " \n",
    " I believe it's going to also build confidence for Michelle or users who can look at some kind of feature based on a benefit based showcase of all the catalog features. Yep, Yep yeah, it'll be a sales tool for us to push it to everybody else. Who needs that sort of capability, right? So that that's a couple things coming up. I was really pleased that Margie got that extended properties thing working 'cause that that that may just take the whole ER studio problem out of the loop. That's a good news, thanks for keeping me in the loop for that. Yeah, I did get some. You know. \n",
    " \n",
    " Like listening in in terms of the HIV claims, data warehouses, building and Alice transferring some of the knowledge for underlying data. And he did mention about one of the problems that you're looking at for the combined data set of person, and I think there is a combined data set which like pipeline which is failing for one of the use cases but other one goes through. I think CVS goes through. Feeling I forget which one, but whatever solution you find, I really appreciate if you could fill me in 'cause I'm trying to build a good understanding of HIV claim data warehouse and the pipelines how they are being used for that domain. Sure, sure I can. I can give you. Quick tour well, let me see if I can get logged in. That's always the first thing, sure, so it. It's a very, very wide file. It has 340 or so attributes in one file, OK? So it it combines claims information with person with with prescribing. Addition with a pharmacy. In the case of CDs, right? All that is just strung together in one big flat box. Wow, OK. And what we do is. Spring we read that flat file into SQL Lite and there's a. Set of steps to to accomplish that and and deal with. There's some episodic encoded numbers that have to be translated and sure, just detail stuff mostly right. Yeah, yeah, it's it's pretty straightforward, sure, but we we get it into SQL Lite and then. Because we we want to pull a dimension and a fact out of that one table, we reuse it so it's all in one pipeline. OK, got it. So this is like the first step is you, do you identify the person fields that you want to pull out? You do select distinct right? Yes, OK and then feed those into the dim person temp table and the normal slowly changing dimension steps after that got it OK type one type 2 and we have a list of similar fields or type 2 here as well like address and. Email and all those extended features extended kind of act like any user they want to keep history on everything until you tell him how expensive it is. OK, yeah, I mean that's the first requirement anyway, like we want to track everything. Yeah. And then then we go back and and hit that same SQL light table again. Yeah, and feed everything into the the fact. OK, I see. So it's a like a fact dimension combined table and we're building fact dimension out of it. And then we're using the same file to build fact out of it, which is basically will combine the we'll just look up those ID's which are in dimension and fill it that ways. Exactly exactly and and you heard the conversation conversation with Jackie about why don't we break the provider out as a dimension as well, because, you know, we had the name and address and everything of the A provider like CBS or BCBS are those providers. \n",
    " \n",
    " Well no, the the like for CVS the pharmacy. OK got it. So yes, that could be another dimension like provided dimension. Yeah and the conversation went that yes we need to do that but we haven't done it yet. Yeah and it'll be pretty straightforward to break it out. It's all the data is in the fact table. We can build the schema for the dimension. Do a little SQL magic to to move the data over there and then set up another pipeline just like we did the the person. Yes, so it'll be a grown up person but a little different because it's not going to be as fancy as a person. It's like maybe fewer fields and a similar dimension I think. Yep, Yep, that's exactly it. So that's where we are on on that. \n",
    " \n",
    " That combined dimension. In fact, I see it has the huge advantage of it should always be In Sync. You know you should never have a person kianna fact record that you can't find the person for right because it's coming from same file. You have the same underlying data. It's like a reverse recursive look up. I don't know what to call it, but it's something you know it's. But on an ongoing basis, it will add value. However, there will be no rejects like ongoing pipeline. Right right one less thing to worry about, yeah. So I finally got logged in. Let me show you where's the share is. There we go. It's just a second, sure. So Ron, I'm clear about until we build the data warehouse, you know? And once you're after, you're done with this demo. \n",
    " \n",
    " I would also like to listen what will happen after the date of their power BI tools that they reports that they build themselves, or whether we maintain it or how do you envision that if there's nothing running off of our data warehouse right now? How it will work in the future? I would get some of your opinion on how it will look like. Right now Kyle is a pretty strong R programmer, got it. So, so his instinct is, you know, grab bar or even grab Python, yes, and go get your data and manipulate it that way. I see other people that work for him are more SQL type people sure and some of them have management studio. Some of them have power BI. Some of them just use Excel because the the data connection in Excel is the same as power BI. What we want them to do is anything that's dashboarding or stuff to do with power BI. He had another tool in mind for awhile and and we convinced him that he should stick with our buy and we'd give him some help, sure. As well as those those. Features of the catalog where you can sample and profile from there because that that was something that this other tool had that RBI doesn't, and that's a huge aid in getting someone new up to speed. Correct, I see. So was that other tool, so are you aware of that other tool that they were evaluating? It was. I don't remember the name, but it's a nice little job that based query tool I got. It is pretty slick interface. Not as much on the presentation side. You know you can't do the dashboarding and stuff like you can't with power beyond sure, but for for reporting it it be you know a nice tool. We just don't wanna support too many tools. Yes. Yes, but power BI I think has most of the features in the market in that segment, right? So it's kind of always in the front in terms of the featured support or the feature scope. Power BI is pretty much the product Microsoft is relying on for. Most of these kind of dashboard. Yeah, yeah definitely. And and it also has the advantage that that you can run things from the server so you can put a big machine behind your your queries and and your manipulations rather than having to run it from your desktop. Sure, yeah, it's more like database cluster like computer separate and then you can get the data from somewhere. Get the compute somewhere else, like a server heavy server and then run big load of splicing and dicing showing dashboards. Yep, Yep. So that that's kind of where we are with them. Ginger's team is supposed to be providing that that power by development support right. I'm not sure how much they've been able to do there. She's she has one power by guy that that was gonna work with Kyle. I haven't heard anymore about that. OK, from an integration standpoint, you know our work ends when we give them the data warehouse and are able to show them how to integrate it with Power BI. Maybe do MVP and then we get like we basically turn into consultative mode. Or do we also manage and own the final reports and dashboards and all the different things that they do on their end? We definitely don't own the dashboards right, but in in that that whole hold their hands support the mode where we're constantly potentially tweaking views for the power. Be I to use or offering assistance and at the same time listening for new requirements because that that a lot of times that's how new requirements for data elements sure come in. Is someone trying to get him on a report and they don't know how to find it. Help me find it and then. Oh, we we need to add a dimension or add something to a dimension. Got it? I see. OK so it's more like you know the core data warehouses will be ready. We'll be adding dimensions or maybe a few things here or there based on the requests. And that's what our main core work would be. We're not going to be consultative and help them create dashboards and final models, but they are more familiar and they own that space and they're. Pretty self sufficient, you know what. Once they get used to the data model, they'll they'll be able to use it that they're. So there there are some user communities that aren't very skilled dealing with databases, and they need a lot of support, and that that's where ginger steam comes in is to, you know, really work with them all the time, or do it for them. I see I see. You know? Thanks for that context Ron. \n",
    " \n",
    " It does make give me a very good perspective of what we're doing and where we're going. Started to regress on the more general topic of Power BI and what to do with data. I think we were talking about the pipeline builder for the HIV claims. The combined pipeline that we were showing showing me on the screen. This is the the one read where we pull in the flat file, got it and it's in a folder and then. We extract the the dim person. Sure, we there's a couple of updates we have to do because the the flat file brings the data to us with a less little bit less intelligence than reading it from the database. There's less metadata around it. And then we run the the slowly changing dimension. One person, yes. And then write it into the the dim person Havel. Then we extract from that same CVS flatfile. Sure for the fact. Running through the fact right and we have that, that optional step for recycling stuff from data stewardship. OK, so as part of the fact there's there's a reject area that can be picked up by data stewardship and that campaign will go through and do fixes or whatever, and once we get stewardship working that way, we'll turn this step on and it'll pull back any corrections. But they've made sure. So that that's. The whole thing I see so and the initial load is going to be for like how does it? How does it differ between the initial load and the daily load? So daily load is simple, I can understand it completely that it will be a file and that file is being in the empty system. We have a file load and in the within the target systems. You know the quote like Row 2312 thirty are creating that daily load for initial load. What will be different like where would that initial big file come from? So the initial load because there are running this right now. \n",
    " \n",
    " \n",
    " And yes, cleaning up data and they've got a couple years worth of history into their database so far. They put a lot of manual effort into cleaning that data and we don't want to try to redo that I see so the initial load will be a conversion of that database to our schema. I see, so that'll be more like a one time migration effort with maybe team app or something like that which can map their column names with our data warehouse specific layout and then. Lift and shift the data. Yep, Yep, so I think once we've gotten past that and that that'll be a project to itself, it's it's more than a one day thing, right, right? Then we'll turn this on. Now the the frequency is monthly. We gonna file a month from all these providers. OK, got it and it's not real consistent, so we'll probably leave these jobs running on a daily basis. Yeah, they just won't do anything until the file lands once a month understood, so we are anticipating like we polling polling on a daily basis. But we know that the frequency is about a month. It could be 28 days or 32 days depending on when they put the file in. And there are occasionally redose where where they make a big mistake and they need to back it out and redo it. So we'll have to support that. You know, we've tagged every attribute that we update or or insert with an identifier that ties back to the ETL pipeline. Run, yes, so we can always find it and take it back out. Or you can do database magic and roll the database back. Yeah, but wouldn't if they update anything wouldn't hour if all the attributes are being tracked with the history. Should it? Should it matter? I mean if we they send one wrong load and one after that they put the right load. I think our framework should handle it. Yeah, yeah, I I think you're right, I think you're right, it's just you know each time something like that happens, you have to think. Think it through carefully and yes. So how to roll it back totally, especially if another lobe is gone in on top of it or something like that, right right? I think we did not discuss a lot about and in framework we don't have like a backup strategy yet whether we back up the certain attributes of. The data warehouse in a way that we can rebuild from, you know, like a restore point kind of thing. You know a feature we don't have it yet, but we can definitely. Databases are backed up every day actually. And so, and the Dbas keep quite a few copies. So if we need to go back a week or two or three. History, do we have that option? OK and then internally within our database we we can pull out an entire ETL run pretty easily, yes. But if there's something where we're doing updates and an update has been applied on top. Then that is hard to unfold. Yeah, yeah, I mean, there are definitely tricky issues which are very unique and they're edge cases that we will think about. Whether it's a one off case or whether we need to build enhance the feature around it. Yep, Yep. OK. So scrolling down. This is that violent out the object schema. Sure, there's a lot of fields we're not using. And it just goes on forever. God, this is like the object, you know, the key mapping basically right. This is the the layout of that file. There are 337 fields. Understand notice the last one has a lot of fields in it, but we don't care, right? So it's like that. Color tab so grateful that we get. This is fixed format. It's a fixed format. OK, so they like after the T 37 field. They're bunch of fields that we don't care about right, and that's why you have to have the length of all these filters 'cause it's adding its way across. Got it? Yep. Sure. And those are the jobs for running context groups. That is where the files land. We pick them up from and. This is where we archive them. OK, so and then everything else works the same as before, right? So these are the source file archive directory, source directory and the source file archive directory, so that's where after we process it. There so our framework job would lift the move the file from source directly to archive directory. Yeah OK, got it and it deletes him off the source too. There's a where is that? Delete flag. And that says archive it and it's turned off for now, OK? I don't see the delete source file flags. All I need to add that for for testing you could see why you wouldn't want to delete this one. Yes, yes, yes totally you know. Otherwise you'll have to put a manual step to bring back the file from all kind directly to source debugging anything. And one other thing that is of interest is. These files are very, very large and. We don't know why you're developing a type of pipeline and run it at every two minutes and things like that. You don't need all that data. Right, right I see. So we're testing they may be using 10 or 15 records or something like that. Yeah, got it. Where did that go? It's not there. I gave created a script for Al. Yeah, here it is. Open this up. So this is the Windows version of a head command. OK. And you you tell it. I see where it's getting data from and where it's writing it to, and that you want the 1st 10 records. Got it? And that very very quickly goes out and gets you 10 records. Puts it into a file where you can access it with the pipeline you want to scale it up to 100 or 1000 that. Easy to do. But this is just out here in in. The S drive. For reuse that's useful. I'll keep that handy with the Windows version of the head command. Always remember it, it's very handy. It looks very handy. Yeah, yeah. I'm show you. Yeah, here's here is that file with a fixed format. That's crazy. The numbers are left justified, Yep. Mainframe generated file. Yeah, it looks like something like. Add a some ADX file. There's so many of them from mainframes that I've seen in the past. Experiences. Yeah, and because we're using a a variable font, it looks like it's out of line, but it's really not right, really. Awesome, so that's what Al has been using to do all of his testing. Kind of, you know, a subset of data like a small amount of data and then figuring it out like getting all the attributes in the data warehouse which match the actual data in what Kyle has been doing on their end without any framework pipeline they are populating the data themselves. Yep Yep. And we need to scale up what we've got in our sandbox database to prove out that the architecture of the junk dimension. And the way we're we're working with the person dimension are correct, right? It'll give us performance improvements and stuff, right? And then we can move forward with the rest of this stuff so that that's why I'm I'm pushing for ginger people to to help us do that. Scale up test and you know, get 6 or 12 months worth of data into the database. Just so we can do some performance checks, I see I see. So the calls that we attended yesterday that's also rated around to this. You mentioned about Johnny is going to pick up something which was not working. And you know, maybe they will pick it up. A lot of framework and pipelines and get to work on little glitch which we were seeing is that related. Is that CVS pipeline is working. T\n",
    " \n",
    " \n",
    " hat's the one we were just looking at. OK, and the Blue Cross one. Fact portion of it is working and Al had just started on the person section. OK, so we we've got a template and so we'll get Johnny up to speed by reviewing the CVS one. Get him running it. I see OK and then Step 2. Or if we get another person is that Blue Cross they can then. Complete the the dim person you know using CDs as a template. Yeah, and get that running yes yes. So it's getting kind of, you know, getting one to run so that they have a quick win. They can see everything flowing through framework and then cloning it and half of the initial work has already been done for them. \n",
    " \n",
    " For the other the Blue Cross person dimension and they can just look at the clone and see where it's different. If it is and fix it and then try it out. Right and then in the meantime, ALS doing the discovery work on the next one because the discovery is really the hard part that the pipeline should be mechanical. So we we may catch up with our or we may not. We will see I see. So how does that you know engagement work around like once we get a requirement then he'll hand it over to AL for doing the discovery? And what kind of information would he need? He would need a flow chart of how. For example, if we're talking about enrollments and memberships, or even need some kind of artifact to kind of give a high level information and then dig deeper, do the research and figure out the fields and the columns. Which would make that report. \n",
    " \n",
    " \n",
    " Basically, it's first we have to understand what data is coming in from the provider, so you know, here's a flat file that give us a layout. Kyle says he he understands what he wants out of it, so that's one conversation is document that sure. Then create the the mapping into the the warehouse. So like the person dimension, are there any new person attributes that we need to add? Or can we just map straight in and then the fact table create a fact table that that will contain the data that that Carl wants and then take those mapping documents? And turn them into pipelines. Got it so I think the first step would just be, you know getting requirement from Kyle and then putting that on SQL based statements to see that we can capture that data and if we can then we can breakdown it into maybe dimensions and then fax and then stitch it into our framework context variables right? And work through the questions about look up tables and code translations and does it map into the junk dimension. Or not, you know it. It's there's some detail in there in that mapping, but sure, it it's mostly just follow the pattern. Got it. Sure, thanks Ron. So Al basically takes care of the discovery portion once we have initial query and sample data experience with the data OK. He's not the only one who can do it. I see he's the one I have got it. Yeah, I was just curious of what are the strengths of people that you have because you know them very experienced while talking on staff meetings. I don't get to get that kind of insight into who's wrong where. Yeah, Alan is very slow. He's very detail oriented which makes him great for digging into new data and documenting. Sure, yes, yes it's not so much of a strength when you're trying to get him to do a pipeline and get it running and hand it off and go on and do the next thing right. He doesn't let go of things very well. I see, yeah, I mean, it's like excellent research. The resource from from that perspective. Yep. Yep. Got it speaking about. I've gotta go talk to him now, sure. Thanks Ron for sharing this. I do have access to a lot of the stuff that you showed me because there's an SC drive. Sorry South Drive, but there may be a few things. Few Nuggets that you have in your notepad++. Could I ask you a favor and whatever, it doesn't have your personal information. Can we have some kind of a common folder in S drive where you can dump some of the excellent resources that you have in my one drive? Best we can copy everything from one drive to a share. Yes, that would be let me let me let me let me see what shares we have. OK and we may have to create a new one, sure. Let let me go see what I can come up with and I'll move everything from one drive out there. Sure, that'll that'll make it a little easier when when you all have to go through and and you know, evaluate whether there's any any sensitive data that needs to be kept or archived after I'm gone right, we will do that Ron, and then I think it'll be a long project, but at least these Nuggets such as you have a project for data fabric implementation. A lot of fine. Research and implementation that you've done in the past may be reusable for any problems that we are facing or new features we are building right right. It's just a matter of no one. Is it out there exactly? OK, well I got a job. Have a Good Friday. Sure Ron you as well. Thank you again for spending time for all this. You know, absolutely thank you NJ. We'll keep dumping stuff on you until you say stop. Is that how it works on? Thanks for sharing that as well. Sometimes stop doesn't work, but yeah. Fair enough I. I think this is going well, but there's a lot that I need to learn as well. You know it's it's. It's a lot of things that you used to do, and you've done in the last four and a half years, and your experience is much more than mine, so it'll take a lot of time for me. But I'll get there. I'll be slow, but I'll probably get there by the end of the year. Maybe I don't know, let's see. Or remember you had to dump this on my replacement as well. That's another challenge. Let's let's see how we'll handle that one, but thanks, Ron. Have a great weekend. If I don't talk to you again today, and thanks again. Bye.\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d43ed050",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i for i in text.split(\". \") if len(i.split(\" \")) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79c13f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e4077dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_clusters(cluster):\n",
    "    # Corpus with example sentences\n",
    "    corpus = cluster\n",
    "\n",
    "    corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "    # Query sentences:\n",
    "    queries = cluster[:5]\n",
    "\n",
    "\n",
    "    # Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "    top_k = min(5, len(corpus))\n",
    "    for query in queries:\n",
    "        query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "        # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "        cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "        top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "        print(\"\\n\\n======================\\n\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "        print(\"\\n======================\\n\")\n",
    "        for score, idx in zip(top_results[0][1:], top_results[1][1:]):\n",
    "            \n",
    "            print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "\n",
    "        \"\"\"\n",
    "        # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "        hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "        hits = hits[0]      #Get the hits for the first query\n",
    "        for hit in hits:\n",
    "            print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84504bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_entities(cluster):\n",
    "    for idx,sent in enumerate(cluster):\n",
    "        # make example sentence\n",
    "        sentence = Sentence(sent)\n",
    "\n",
    "        # predict NER tags\n",
    "        tagger.predict(sentence)\n",
    "\n",
    "        # print sentence\n",
    "        # print(sentence)\n",
    "\n",
    "        # print predicted NER spans\n",
    "    #     print('The following NER tags are found:')\n",
    "        # iterate over entities and print\n",
    "        for entity in sentence.get_spans('ner'):\n",
    "            print(f\"{entity} => {idx}:  {sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6569f408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  1\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: It's a very, very wide file\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "These files are very, very large and (Score: 0.7085)\n",
      "Yeah, here's here is that file with a fixed format (Score: 0.6190)\n",
      "This is the the layout of that file (Score: 0.5692)\n",
      "It's a fixed format (Score: 0.5355)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: In the case of CDs, right? All that is just strung together in one big flat box\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "Complete the the dim person you know using CDs as a template (Score: 0.4542)\n",
      "These files are very, very large and (Score: 0.2962)\n",
      "\n",
      " \n",
      " \n",
      " Basically, it's first we have to understand what data is coming in from the provider, so you know, here's a flat file that give us a layout (Score: 0.2607)\n",
      "That is where the files land (Score: 0.2534)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Spring we read that flat file into SQL Lite and there's a\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "This is the the one read where we pull in the flat file, got it and it's in a folder and then (Score: 0.5650)\n",
      "Sure, we there's a couple of updates we have to do because the the flat file brings the data to us with a less little bit less intelligence than reading it from the database (Score: 0.5394)\n",
      "Yeah, here's here is that file with a fixed format (Score: 0.4104)\n",
      "Then we extract from that same CVS flatfile (Score: 0.3881)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: There's some episodic encoded numbers that have to be translated and sure, just detail stuff mostly right\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "It's a fixed format (Score: 0.3463)\n",
      "Yeah, here's here is that file with a fixed format (Score: 0.3048)\n",
      "These files are very, very large and (Score: 0.2722)\n",
      "\n",
      " \n",
      " \n",
      " Basically, it's first we have to understand what data is coming in from the provider, so you know, here's a flat file that give us a layout (Score: 0.2706)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: You know you should never have a person kianna fact record that you can't find the person for right because it's coming from same file\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "Then we extract from that same CVS flatfile (Score: 0.3504)\n",
      "Sure, we there's a couple of updates we have to do because the the flat file brings the data to us with a less little bit less intelligence than reading it from the database (Score: 0.3472)\n",
      "Complete the the dim person you know using CDs as a template (Score: 0.3315)\n",
      "Yeah OK, got it and it deletes him off the source too (Score: 0.3246)\n",
      "\n",
      "Cluster  2\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: You could be the repository of that information until we get a replacement for a move on\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      " \n",
      " \n",
      " And yes, cleaning up data and they've got a couple years worth of history into their database so far (Score: 0.4414)\n",
      "Yeah, but wouldn't if they update anything wouldn't hour if all the attributes are being tracked with the history (Score: 0.4400)\n",
      "Data at one place and it's going to be the complete metadata that we need for catalog (Score: 0.4242)\n",
      "Sure, that'll that'll make it a little easier when when you all have to go through and and you know, evaluate whether there's any any sensitive data that needs to be kept or archived after I'm gone right, we will do that Ron, and then I think it'll be a long project, but at least these Nuggets such as you have a project for data fabric implementation (Score: 0.4109)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: So it connects to the secret server, gets a JSON load payload back, and then we parse that JSON to connect our datasets\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "I see where it's getting data from and where it's writing it to, and that you want the 1st 10 records (Score: 0.3299)\n",
      "Once they get used to the data model, they'll they'll be able to use it that they're (Score: 0.3156)\n",
      "Kind of, you know, a subset of data like a small amount of data and then figuring it out like getting all the attributes in the data warehouse which match the actual data in what Kyle has been doing on their end without any framework pipeline they are populating the data themselves (Score: 0.2926)\n",
      "They put a lot of manual effort into cleaning that data and we don't want to try to redo that I see so the initial load will be a conversion of that database to our schema (Score: 0.2912)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: To maintain a sink or somehow you know that, like with some metadata information, that everything is In Sync with a daily cadence or whatever like and number of minutes cadence\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "Features of the catalog where you can sample and profile from there because that that was something that this other tool had that RBI doesn't, and that's a huge aid in getting someone new up to speed (Score: 0.4190)\n",
      "Because we we want to pull a dimension and a fact out of that one table, we reuse it so it's all in one pipeline (Score: 0.4037)\n",
      "Data at one place and it's going to be the complete metadata that we need for catalog (Score: 0.3935)\n",
      "Databases are backed up every day actually (Score: 0.3791)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: \n",
      "\n",
      "Margie - Extended Logging\n",
      "\n",
      "Well, I was talking to Margie and she said she had tried to get the extended logging from talent data catalog and didn't really see much difference\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "Stitching the talent data catalog or the the data integration stuff (Score: 0.5187)\n",
      "Features of the catalog where you can sample and profile from there because that that was something that this other tool had that RBI doesn't, and that's a huge aid in getting someone new up to speed (Score: 0.4772)\n",
      "I've been playing with pushing all of the the metadata that's documented in ER studio into extended properties in the database, and the experiment was does data catalog see those extended properties and so far the answer is yes, so she may be about to make a huge step forward and get all the metadata into data catalog (Score: 0.4294)\n",
      "So we're testing they may be using 10 or 15 records or something like that (Score: 0.4180)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: There's kind of a a mismatch if we pull our database schemas from ER studio and from the live database\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "I've been playing with pushing all of the the metadata that's documented in ER studio into extended properties in the database, and the experiment was does data catalog see those extended properties and so far the answer is yes, so she may be about to make a huge step forward and get all the metadata into data catalog (Score: 0.5329)\n",
      "They put a lot of manual effort into cleaning that data and we don't want to try to redo that I see so the initial load will be a conversion of that database to our schema (Score: 0.5227)\n",
      "It doesn't tie out exactly 1 to one with the ER studio, and what margin is working once if we put catalog in the middle and we stitch everything from the databases, which will be like 1 to one stitching from a catalog perspective and on the other hand, if ER studio also we are able to switch to catalog then we get all the (Score: 0.5138)\n",
      "Yes it will stitch well to the database because it the the database names match up (Score: 0.4538)\n",
      "\n",
      "Cluster  3\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: So yeah, I will do that and I'm familiar with that job\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "Yes, that'll be helpful, and yeah, that'll be helpful in many ways around (Score: 0.4305)\n",
      "Sure, that sounds good and she's also been working with it to (Score: 0.4282)\n",
      "Is it out there exactly? OK, well I got a job (Score: 0.4117)\n",
      "I think this is going well, but there's a lot that I need to learn as well (Score: 0.3643)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: I don't think he got much further than than just describing it the way you did\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "So just to get a better handle of what you said and I'll try to rephrase (Score: 0.4286)\n",
      "Yeah yeah, and he was really really good at working with the business and and gathering requirements (Score: 0.2991)\n",
      "So yeah, I think on that's there with a lot of people, even sometimes the year and I used to talk in private and he also mentioned some frustration that we are not moving that fast (Score: 0.2881)\n",
      "You know? Thanks for that context Ron (Score: 0.2792)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: I will set something up so that he can transfer the repository of information to me\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "Could I ask you a favor and whatever, it doesn't have your personal information (Score: 0.3870)\n",
      "He had another tool in mind for awhile and and we convinced him that he should stick with our buy and we'd give him some help, sure (Score: 0.3605)\n",
      "So yeah, I will do that and I'm familiar with that job (Score: 0.3597)\n",
      "Yes, and I'm gonna talk to him about getting a A (Score: 0.3125)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: I'll capture it somewhere and whenever we have the replacement, I can do the transition\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "Let let me go see what I can come up with and I'll move everything from one drive out there (Score: 0.3357)\n",
      "Sure, sure I can (Score: 0.3145)\n",
      "I can give you (Score: 0.3123)\n",
      "I'll be slow, but I'll probably get there by the end of the year (Score: 0.2749)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Yeah yeah, and he was really really good at working with the business and and gathering requirements\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "He had another tool in mind for awhile and and we convinced him that he should stick with our buy and we'd give him some help, sure (Score: 0.3603)\n",
      "Yes, and I'm gonna talk to him about getting a A (Score: 0.3523)\n",
      "Yeah, I was just curious of what are the strengths of people that you have because you know them very experienced while talking on staff meetings (Score: 0.3123)\n",
      "So plus this other place, right? He's better (Score: 0.3069)\n",
      "\n",
      "Cluster  4\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Rons 1-on-1\n",
      "\n",
      "Amuthan Leaving: \n",
      "One of the things he was working on was a Python job to sync the on Prem secret server secrets with Azure Key Vault that's been kind of on hold, but it's based off of our Python job so\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "His core technology is snowflake and boy that sure would have been handy when we get that far in the Azure project, but (Score: 0.3680)\n",
      "Great, thank you, MJ thank you.\n",
      "\n",
      "\n",
      "\n",
      "I confirmed it in one of the meetings and Reese confirmed that he didn't give any details when it's the last day and whatnot where it's going to be a big loss for specially the Azure project, especially from a data governance and all the other things that are brought to the table (Score: 0.3513)\n",
      "A lot of framework and pipelines and get to work on little glitch which we were seeing is that related (Score: 0.2521)\n",
      "In addition replacement, we will just use another API from the keyboard and the kind of (Score: 0.2512)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: He's gonna hand over whatever information he's gathered on that on the requirements\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "So how does that you know engagement work around like once we get a requirement then he'll hand it over to AL for doing the discovery? And what kind of information would he need? He would need a flow chart of how (Score: 0.5300)\n",
      "OK, yeah, I mean that's the first requirement anyway, like we want to track everything (Score: 0.5171)\n",
      "Who needs that sort of capability, right? So that that's a couple things coming up (Score: 0.4243)\n",
      "Fact portion of it is working and Al had just started on the person section (Score: 0.3775)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: In addition replacement, we will just use another API from the keyboard and the kind of\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "OK and we may have to create a new one, sure (Score: 0.3821)\n",
      "You know a feature we don't have it yet, but we can definitely (Score: 0.3316)\n",
      "Power BI is pretty much the product Microsoft is relying on for (Score: 0.3145)\n",
      "I think our framework should handle it (Score: 0.2960)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Obviously you'd need an on demand option if you're sticking with daily\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "Now the the frequency is monthly (Score: 0.3756)\n",
      "OK, got it and it's not real consistent, so we'll probably leave these jobs running on a daily basis (Score: 0.3610)\n",
      "So if we need to go back a week or two or three (Score: 0.3341)\n",
      "But we know that the frequency is about a month (Score: 0.3258)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Great, thank you, MJ thank you.\n",
      "\n",
      "\n",
      "\n",
      "I confirmed it in one of the meetings and Reese confirmed that he didn't give any details when it's the last day and whatnot where it's going to be a big loss for specially the Azure project, especially from a data governance and all the other things that are brought to the table\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      " \n",
      " I would also like to listen what will happen after the date of their power BI tools that they reports that they build themselves, or whether we maintain it or how do you envision that if there's nothing running off of our data warehouse right now? How it will work in the future? I would get some of your opinion on how it will look like (Score: 0.4880)\n",
      "His core technology is snowflake and boy that sure would have been handy when we get that far in the Azure project, but (Score: 0.4361)\n",
      "OK, so as part of the fact there's there's a reject area that can be picked up by data stewardship and that campaign will go through and do fixes or whatever, and once we get stewardship working that way, we'll turn this step on and it'll pull back any corrections (Score: 0.3538)\n",
      "Yeah, they just won't do anything until the file lands once a month understood, so we are anticipating like we polling polling on a daily basis (Score: 0.3517)\n",
      "\n",
      "Cluster  5\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Yeah, there's no no movement on it yet, but just you\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "It's just a matter of no one (Score: 0.3398)\n",
      "And it just goes on forever (Score: 0.3333)\n",
      "Yeah, here it is (Score: 0.3250)\n",
      "It's just a second, sure (Score: 0.2860)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: I think you're familiar with it\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "I don't know what to call it, but it's something you know it's (Score: 0.4546)\n",
      "Yeah, yeah, I I think you're right, I think you're right, it's just you know each time something like that happens, you have to think (Score: 0.4210)\n",
      "So I think that's what they settled on (Score: 0.3856)\n",
      "You know it's it's (Score: 0.3825)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: So I think that's what they settled on\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "I think you're familiar with it (Score: 0.3855)\n",
      "Yeah, yeah, I I think you're right, I think you're right, it's just you know each time something like that happens, you have to think (Score: 0.3436)\n",
      "Then that is hard to unfold (Score: 0.3258)\n",
      "OK, so that that sounds reasonable (Score: 0.3175)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: OK, so that that sounds reasonable\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "So I think that's what they settled on (Score: 0.3176)\n",
      "\n",
      "\n",
      "Sure would count yes (Score: 0.3143)\n",
      "Then that is hard to unfold (Score: 0.3139)\n",
      "Yep, Yep, that's exactly it (Score: 0.3022)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Yes one person says\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "======================\n",
      "\n",
      "And you you tell it (Score: 0.3659)\n",
      "He's not the only one who can do it (Score: 0.3492)\n",
      "It's just a matter of no one (Score: 0.3332)\n",
      "I see he's the one I have got it (Score: 0.3180)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model for computing sentence embeddings. We use one trained for similar questions detection\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "corpus_embeddings = embedder.encode(sentences)\n",
    "\n",
    "# Perform kmean clustering\n",
    "num_clusters = 5\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(sentences[sentence_id])\n",
    "\n",
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i+1)\n",
    "    display_clusters(cluster)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa7aa8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  1\n",
      "Span [16]: \"one\"   [− Labels: CARDINAL (0.8841)] => 1:  In the case of CDs, right? All that is just strung together in one big flat box\n",
      "Span [7]: \"CVS\"   [− Labels: ORG (0.8883)] => 8:  Then we extract from that same CVS flatfile\n",
      "Span [6,7,8]: \"Row 2312 thirty\"   [− Labels: WORK_OF_ART (0.4403)] => 11:  You know the quote like Row 2312 thirty are creating that daily load for initial load\n",
      "Span [4,5]: \"28 days\"   [− Labels: DATE (0.9651)] => 13:  It could be 28 days or 32 days depending on when they put the file in\n",
      "Span [7,8]: \"32 days\"   [− Labels: DATE (0.9697)] => 13:  It could be 28 days or 32 days depending on when they put the file in\n",
      "Span [21]: \"100\"   [− Labels: CARDINAL (0.8901)] => 29:  Puts it into a file where you can access it with the pipeline you want to scale it up to 100 or 1000 that\n",
      "Span [23]: \"1000\"   [− Labels: CARDINAL (0.6346)] => 29:  Puts it into a file where you can access it with the pipeline you want to scale it up to 100 or 1000 that\n",
      "Span [8]: \"Windows\"   [− Labels: PRODUCT (0.8827)] => 31:  I'll keep that handy with the Windows version of the head command\n",
      "Span [19]: \"SC\"   [− Labels: ORG (0.4642)] => 37:  I do have access to a lot of the stuff that you showed me because there's an SC drive\n",
      "Span [27]: \"one\"   [− Labels: CARDINAL (0.8244)] => 39:  Can we have some kind of a common folder in S drive where you can dump some of the excellent resources that you have in my one drive? Best we can copy everything from one drive to a share\n",
      "Span [36]: \"one\"   [− Labels: CARDINAL (0.8206)] => 39:  Can we have some kind of a common folder in S drive where you can dump some of the excellent resources that you have in my one drive? Best we can copy everything from one drive to a share\n",
      "\n",
      "Cluster  2\n",
      "Span [11]: \"Margie\"   [− Labels: PERSON (0.9984)] => 3:  \n",
      "\n",
      "Margie - Extended Logging\n",
      "\n",
      "Well, I was talking to Margie and she said she had tried to get the extended logging from talent data catalog and didn't really see much difference\n",
      "Span [7,8,9]: \"1 to one\"   [− Labels: CARDINAL (0.5963)] => 10:  It doesn't tie out exactly 1 to one with the ER studio, and what margin is working once if we put catalog in the middle and we stitch everything from the databases, which will be like 1 to one stitching from a catalog perspective and on the other hand, if ER studio also we are able to switch to catalog then we get all the\n",
      "Span [40,41,42]: \"1 to one\"   [− Labels: CARDINAL (0.7078)] => 10:  It doesn't tie out exactly 1 to one with the ER studio, and what margin is working once if we put catalog in the middle and we stitch everything from the databases, which will be like 1 to one stitching from a catalog perspective and on the other hand, if ER studio also we are able to switch to catalog then we get all the\n",
      "Span [3]: \"one\"   [− Labels: CARDINAL (0.8989)] => 11:  Data at one place and it's going to be the complete metadata that we need for catalog\n",
      "Span [12]: \"10\"   [− Labels: CARDINAL (0.9949)] => 12:  You can sample data from the database and you know keep 10 records or 100 records so people can see what your data looks like\n",
      "Span [15]: \"100\"   [− Labels: CARDINAL (0.982)] => 12:  You can sample data from the database and you know keep 10 records or 100 records so people can see what your data looks like\n",
      "Span [5]: \"one\"   [− Labels: CARDINAL (0.864)] => 13:  \n",
      "\n",
      "\n",
      "That that's always one of the first things you do when you're learning a new data set\n",
      "Span [8]: \"first\"   [− Labels: ORDINAL (0.9991)] => 13:  \n",
      "\n",
      "\n",
      "That that's always one of the first things you do when you're learning a new data set\n",
      "Span [17]: \"first\"   [− Labels: ORDINAL (0.965)] => 15:  Do you know, for example, any tool would give you a display off the first few records, how they look like and also it has masking I believe so we can mask certain fields\n",
      "Span [8]: \"Michelle\"   [− Labels: PERSON (0.9976)] => 16:  Data catalog consultant in sometime you know Michelle's financial data warehouse is going to be the first one that's complete enough that it it's ready for catalog and Michelle is very interested in seeing the product right? So that's why I've been working on those SQL statements to tie the stuff from studio into catalog, right?\n",
      "\n",
      " And then then we can automate that stuff and get an expert in to show us how to use catalog 'cause it's changed a bit since we took training\n",
      "Span [18]: \"first\"   [− Labels: ORDINAL (0.9922)] => 16:  Data catalog consultant in sometime you know Michelle's financial data warehouse is going to be the first one that's complete enough that it it's ready for catalog and Michelle is very interested in seeing the product right? So that's why I've been working on those SQL statements to tie the stuff from studio into catalog, right?\n",
      "\n",
      " And then then we can automate that stuff and get an expert in to show us how to use catalog 'cause it's changed a bit since we took training\n",
      "Span [32]: \"Michelle\"   [− Labels: PERSON (0.999)] => 16:  Data catalog consultant in sometime you know Michelle's financial data warehouse is going to be the first one that's complete enough that it it's ready for catalog and Michelle is very interested in seeing the product right? So that's why I've been working on those SQL statements to tie the stuff from studio into catalog, right?\n",
      "\n",
      " And then then we can automate that stuff and get an expert in to show us how to use catalog 'cause it's changed a bit since we took training\n",
      "Span [6]: \"one\"   [− Labels: CARDINAL (0.7932)] => 18:  And he did mention about one of the problems that you're looking at for the combined data set of person, and I think there is a combined data set which like pipeline which is failing for one of the use cases but other one goes through\n",
      "Span [39]: \"one\"   [− Labels: CARDINAL (0.6086)] => 18:  And he did mention about one of the problems that you're looking at for the combined data set of person, and I think there is a combined data set which like pipeline which is failing for one of the use cases but other one goes through\n",
      "Span [5]: \"one\"   [− Labels: CARDINAL (0.7768)] => 19:  Feeling I forget which one, but whatever solution you find, I really appreciate if you could fill me in 'cause I'm trying to build a good understanding of HIV claim data warehouse and the pipelines how they are being used for that domain\n",
      "Span [3,4,5]: \"340 or so\"   [− Labels: CARDINAL (0.7993)] => 20:  It has 340 or so attributes in one file, OK? So it it combines claims information with person with with prescribing\n",
      "Span [8]: \"one\"   [− Labels: CARDINAL (0.7088)] => 20:  It has 340 or so attributes in one file, OK? So it it combines claims information with person with with prescribing\n",
      "Span [15]: \"one\"   [− Labels: CARDINAL (0.7898)] => 22:  Because we we want to pull a dimension and a fact out of that one table, we reuse it so it's all in one pipeline\n",
      "Span [26]: \"one\"   [− Labels: CARDINAL (0.9594)] => 22:  Because we we want to pull a dimension and a fact out of that one table, we reuse it so it's all in one pipeline\n",
      "Span [6]: \"first\"   [− Labels: ORDINAL (1.0)] => 23:  So this is like the first step is you, do you identify the person fields that you want to pull out? You do select distinct right? Yes, OK and then feed those into the dim person temp table and the normal slowly changing dimension steps after that got it OK type one type 2 and we have a list of similar fields or type 2 here as well like address and\n",
      "Span [56]: \"one\"   [− Labels: CARDINAL (0.9006)] => 23:  So this is like the first step is you, do you identify the person fields that you want to pull out? You do select distinct right? Yes, OK and then feed those into the dim person temp table and the normal slowly changing dimension steps after that got it OK type one type 2 and we have a list of similar fields or type 2 here as well like address and\n",
      "Span [58]: \"2\"   [− Labels: CARDINAL (0.9339)] => 23:  So this is like the first step is you, do you identify the person fields that you want to pull out? You do select distinct right? Yes, OK and then feed those into the dim person temp table and the normal slowly changing dimension steps after that got it OK type one type 2 and we have a list of similar fields or type 2 here as well like address and\n",
      "Span [69]: \"2\"   [− Labels: CARDINAL (0.8361)] => 23:  So this is like the first step is you, do you identify the person fields that you want to pull out? You do select distinct right? Yes, OK and then feed those into the dim person temp table and the normal slowly changing dimension steps after that got it OK type one type 2 and we have a list of similar fields or type 2 here as well like address and\n",
      "Span [2]: \"Ron\"   [− Labels: PERSON (0.9996)] => 32:  So Ron, I'm clear about until we build the data warehouse, you know? And once you're after, you're done with this demo\n",
      "Span [6]: \"Excel\"   [− Labels: PRODUCT (0.9993)] => 35:  Some of them just use Excel because the the data connection in Excel is the same as power BI\n",
      "Span [13]: \"Excel\"   [− Labels: PRODUCT (0.9959)] => 35:  Some of them just use Excel because the the data connection in Excel is the same as power BI\n",
      "Span [24]: \"RBI\"   [− Labels: ORG (0.9573)] => 36:  Features of the catalog where you can sample and profile from there because that that was something that this other tool had that RBI doesn't, and that's a huge aid in getting someone new up to speed\n",
      "Span [31,32]: \"Power BI\"   [− Labels: ORG (0.7071)] => 39:  OK, from an integration standpoint, you know our work ends when we give them the data warehouse and are able to show them how to integrate it with Power BI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [10,11]: \"Power BI\"   [− Labels: ORG (0.6745)] => 44:  Started to regress on the more general topic of Power BI and what to do with data\n",
      "Span [11,12,13]: \"a couple years\"   [− Labels: DATE (0.6899)] => 46:  \n",
      " \n",
      " \n",
      " And yes, cleaning up data and they've got a couple years worth of history into their database so far\n",
      "Span [11]: \"one\"   [− Labels: CARDINAL (0.8513)] => 48:  I see, so that'll be more like a one time migration effort with maybe team app or something like that which can map their column names with our data warehouse specific layout and then\n",
      "Span [23]: \"ETL\"   [− Labels: ORG (0.521)] => 50:  You know, we've tagged every attribute that we update or or insert with an identifier that ties back to the ETL pipeline\n",
      "Span [3]: \"337\"   [− Labels: CARDINAL (0.9693)] => 58:  There are 337 fields\n",
      "Span [9]: \"10\"   [− Labels: CARDINAL (0.9547)] => 61:  So we're testing they may be using 10 or 15 records or something like that\n",
      "Span [11]: \"15\"   [− Labels: CARDINAL (0.5298)] => 61:  So we're testing they may be using 10 or 15 records or something like that\n",
      "Span [22]: \"1st\"   [− Labels: ORDINAL (0.9789)] => 62:  I see where it's getting data from and where it's writing it to, and that you want the 1st 10 records\n",
      "Span [23]: \"10\"   [− Labels: CARDINAL (0.9149)] => 62:  I see where it's getting data from and where it's writing it to, and that you want the 1st 10 records\n",
      "Span [38]: \"Kyle\"   [− Labels: PERSON (0.9517)] => 63:  Kind of, you know, a subset of data like a small amount of data and then figuring it out like getting all the attributes in the data warehouse which match the actual data in what Kyle has been doing on their end without any framework pipeline they are populating the data themselves\n",
      "Span [9]: \"6\"   [− Labels: CARDINAL (0.9505)] => 65:  Scale up test and you know, get 6 or 12 months worth of data into the database\n",
      "Span [11,12]: \"12 months\"   [− Labels: DATE (0.7224)] => 65:  Scale up test and you know, get 6 or 12 months worth of data into the database\n",
      "Span [43]: \"Carl\"   [− Labels: PERSON (0.9983)] => 68:  So like the person dimension, are there any new person attributes that we need to add? Or can we just map straight in and then the fact table create a fact table that that will contain the data that that Carl wants and then take those mapping documents? And turn them into pipelines\n",
      "Span [7]: \"first\"   [− Labels: ORDINAL (1.0)] => 69:  Got it so I think the first step would just be, you know getting requirement from Kyle and then putting that on SQL based statements to see that we can capture that data and if we can then we can breakdown it into maybe dimensions and then fax and then stitch it into our framework context variables right? And work through the questions about look up tables and code translations and does it map into the junk dimension\n",
      "Span [18]: \"Kyle\"   [− Labels: PERSON (0.9956)] => 69:  Got it so I think the first step would just be, you know getting requirement from Kyle and then putting that on SQL based statements to see that we can capture that data and if we can then we can breakdown it into maybe dimensions and then fax and then stitch it into our framework context variables right? And work through the questions about look up tables and code translations and does it map into the junk dimension\n",
      "Span [2]: \"Al\"   [− Labels: PERSON (0.7387)] => 71:  So Al basically takes care of the discovery portion once we have initial query and sample data experience with the data OK\n",
      "Span [50]: \"Ron\"   [− Labels: PERSON (0.9993)] => 73:  Sure, that'll that'll make it a little easier when when you all have to go through and and you know, evaluate whether there's any any sensitive data that needs to be kept or archived after I'm gone right, we will do that Ron, and then I think it'll be a long project, but at least these Nuggets such as you have a project for data fabric implementation\n",
      "\n",
      "Cluster  3\n",
      "Span [4]: \"Amazon\"   [− Labels: ORG (0.9144)] => 9:  Anything else on Amazon's plate\n",
      "Span [1]: \"Ron\"   [− Labels: PERSON (0.9984)] => 10:  Ron that I need to take care about\n",
      "Span [5]: \"two\"   [− Labels: CARDINAL (0.9946)] => 16:  OK, which are two things that Kyle McKay is asked for\n",
      "Span [8,9]: \"Kyle McKay\"   [− Labels: PERSON (0.8175)] => 16:  OK, which are two things that Kyle McKay is asked for\n",
      "Span [3]: \"Kyle\"   [− Labels: PERSON (0.9988)] => 26:  Right now Kyle is a pretty strong R programmer, got it\n",
      "Span [8]: \"Ron\"   [− Labels: PERSON (0.9964)] => 32:  You know? Thanks for that context Ron\n",
      "Span [4]: \"Johnny\"   [− Labels: PERSON (0.9605)] => 38:  You mentioned about Johnny is going to pick up something which was not working\n",
      "Span [1]: \"Kyle\"   [− Labels: PERSON (0.9988)] => 39:  Kyle says he he understands what he wants out of it, so that's one conversation is document that sure\n",
      "Span [16]: \"one\"   [− Labels: CARDINAL (0.8147)] => 39:  Kyle says he he understands what he wants out of it, so that's one conversation is document that sure\n",
      "Span [2]: \"Ron\"   [− Labels: PERSON (0.9998)] => 45:  Thanks Ron for sharing this\n",
      "Span [4]: \"Friday\"   [− Labels: DATE (0.9872)] => 52:  Have a Good Friday\n",
      "Span [2]: \"Ron\"   [− Labels: PERSON (0.9984)] => 53:  Sure Ron you as well\n",
      "Span [18,19,20,21,22,23,24]: \"the last four and a half years\"   [− Labels: DATE (0.7557)] => 58:  It's a lot of things that you used to do, and you've done in the last four and a half years, and your experience is much more than mine, so it'll take a lot of time for me\n",
      "Span [13,14,15,16,17]: \"the end of the year\"   [− Labels: DATE (0.8834)] => 60:  I'll be slow, but I'll probably get there by the end of the year\n",
      "Span [16]: \"Ron\"   [− Labels: PERSON (0.9989)] => 61:  Let's let's see how we'll handle that one, but thanks, Ron\n",
      "\n",
      "Cluster  4\n",
      "Span [1]: \"Rons\"   [− Labels: PERSON (0.9285)] => 0:  Rons 1-on-1\n",
      "\n",
      "Amuthan Leaving: \n",
      "One of the things he was working on was a Python job to sync the on Prem secret server secrets with Azure Key Vault that's been kind of on hold, but it's based off of our Python job so\n",
      "Span [3]: \"Amuthan\"   [− Labels: PERSON (0.6728)] => 0:  Rons 1-on-1\n",
      "\n",
      "Amuthan Leaving: \n",
      "One of the things he was working on was a Python job to sync the on Prem secret server secrets with Azure Key Vault that's been kind of on hold, but it's based off of our Python job so\n",
      "Span [6]: \"One\"   [− Labels: CARDINAL (0.9948)] => 0:  Rons 1-on-1\n",
      "\n",
      "Amuthan Leaving: \n",
      "One of the things he was working on was a Python job to sync the on Prem secret server secrets with Azure Key Vault that's been kind of on hold, but it's based off of our Python job so\n",
      "Span [16]: \"Python\"   [− Labels: ORG (0.5515)] => 0:  Rons 1-on-1\n",
      "\n",
      "Amuthan Leaving: \n",
      "One of the things he was working on was a Python job to sync the on Prem secret server secrets with Azure Key Vault that's been kind of on hold, but it's based off of our Python job so\n",
      "Span [27,28,29]: \"Azure Key Vault\"   [− Labels: PRODUCT (0.4227)] => 0:  Rons 1-on-1\n",
      "\n",
      "Amuthan Leaving: \n",
      "One of the things he was working on was a Python job to sync the on Prem secret server secrets with Azure Key Vault that's been kind of on hold, but it's based off of our Python job so\n",
      "Span [6]: \"MJ\"   [− Labels: PERSON (0.9998)] => 4:  Great, thank you, MJ thank you.\n",
      "\n",
      "\n",
      "\n",
      "I confirmed it in one of the meetings and Reese confirmed that he didn't give any details when it's the last day and whatnot where it's going to be a big loss for specially the Azure project, especially from a data governance and all the other things that are brought to the table\n",
      "Span [14]: \"one\"   [− Labels: CARDINAL (0.9753)] => 4:  Great, thank you, MJ thank you.\n",
      "\n",
      "\n",
      "\n",
      "I confirmed it in one of the meetings and Reese confirmed that he didn't give any details when it's the last day and whatnot where it's going to be a big loss for specially the Azure project, especially from a data governance and all the other things that are brought to the table\n",
      "Span [19]: \"Reese\"   [− Labels: PERSON (0.9984)] => 4:  Great, thank you, MJ thank you.\n",
      "\n",
      "\n",
      "\n",
      "I confirmed it in one of the meetings and Reese confirmed that he didn't give any details when it's the last day and whatnot where it's going to be a big loss for specially the Azure project, especially from a data governance and all the other things that are brought to the table\n",
      "Span [31,32,33]: \"the last day\"   [− Labels: DATE (0.8098)] => 4:  Great, thank you, MJ thank you.\n",
      "\n",
      "\n",
      "\n",
      "I confirmed it in one of the meetings and Reese confirmed that he didn't give any details when it's the last day and whatnot where it's going to be a big loss for specially the Azure project, especially from a data governance and all the other things that are brought to the table\n",
      "Span [21]: \"Azure\"   [− Labels: LOC (0.547)] => 5:  His core technology is snowflake and boy that sure would have been handy when we get that far in the Azure project, but\n",
      "Span [9,10,11]: \"Cornelius from Talent\"   [− Labels: WORK_OF_ART (0.6584)] => 13:  \n",
      "\n",
      "\n",
      "And then we've got a call with Cornelius from Talent scheduled next week\n",
      "Span [13,14]: \"next week\"   [− Labels: DATE (0.8715)] => 13:  \n",
      "\n",
      "\n",
      "And then we've got a call with Cornelius from Talent scheduled next week\n",
      "Span [11]: \"Michelle\"   [− Labels: PERSON (0.9801)] => 14:  \n",
      " \n",
      " I believe it's going to also build confidence for Michelle or users who can look at some kind of feature based on a benefit based showcase of all the catalog features\n",
      "Span [14,15]: \"a couple\"   [− Labels: TIME (0.8558)] => 16:  Who needs that sort of capability, right? So that that's a couple things coming up\n",
      "Span [6]: \"Margie\"   [− Labels: PERSON (0.9878)] => 17:  I was really pleased that Margie got that extended properties thing working 'cause that that that may just take the whole ER studio problem out of the loop\n",
      "Span [3]: \"CVS\"   [− Labels: ORG (0.8728)] => 19:  I think CVS goes through\n",
      "Span [10]: \"first\"   [− Labels: ORDINAL (0.9994)] => 23:  OK, yeah, I mean that's the first requirement anyway, like we want to track everything\n",
      "Span [11]: \"Jackie\"   [− Labels: PERSON (0.9992)] => 24:  Exactly exactly and and you heard the conversation conversation with Jackie about why don't we break the provider out as a dimension as well, because, you know, we had the name and address and everything of the A provider like CBS or BCBS are those providers\n",
      "Span [45]: \"CBS\"   [− Labels: ORG (0.9992)] => 24:  Exactly exactly and and you heard the conversation conversation with Jackie about why don't we break the provider out as a dimension as well, because, you know, we had the name and address and everything of the A provider like CBS or BCBS are those providers\n",
      "Span [47]: \"BCBS\"   [− Labels: ORG (0.9924)] => 24:  Exactly exactly and and you heard the conversation conversation with Jackie about why don't we break the provider out as a dimension as well, because, you know, we had the name and address and everything of the A provider like CBS or BCBS are those providers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span [8]: \"CVS\"   [− Labels: ORG (0.9506)] => 25:  \n",
      " \n",
      " Well no, the the like for CVS the pharmacy\n",
      "Span [16,17]: \"In Sync\"   [− Labels: ORG (0.9456)] => 28:  In fact, I see it has the huge advantage of it should always be In Sync\n",
      "Span [1,2]: \"Power BI\"   [− Labels: ORG (0.7088)] => 39:  Power BI is pretty much the product Microsoft is relying on for\n",
      "Span [8]: \"Microsoft\"   [− Labels: ORG (0.9988)] => 39:  Power BI is pretty much the product Microsoft is relying on for\n",
      "Span [1]: \"Ginger\"   [− Labels: PERSON (0.9857)] => 44:  Ginger's team is supposed to be providing that that power by development support right\n",
      "Span [31]: \"one\"   [− Labels: CARDINAL (0.8722)] => 55:  Yep, Yep, so I think once we've gotten past that and that that'll be a project to itself, it's it's more than a one day thing, right, right? Then we'll turn this on\n",
      "Span [6]: \"monthly\"   [− Labels: DATE (0.9963)] => 56:  Now the the frequency is monthly\n",
      "Span [4,5]: \"a month\"   [− Labels: DATE (0.821)] => 57:  We gonna file a month from all these providers\n",
      "Span [8,9,10]: \"about a month\"   [− Labels: DATE (0.8864)] => 60:  But we know that the frequency is about a month\n",
      "Span [14]: \"one\"   [− Labels: CARDINAL (0.9979)] => 62:  Should it? Should it matter? I mean if we they send one wrong load and one after that they put the right load\n",
      "Span [8,9]: \"a week\"   [− Labels: DATE (0.7758)] => 65:  So if we need to go back a week or two or three\n",
      "Span [11]: \"two\"   [− Labels: CARDINAL (0.9676)] => 65:  So if we need to go back a week or two or three\n",
      "Span [13]: \"three\"   [− Labels: CARDINAL (0.9904)] => 65:  So if we need to go back a week or two or three\n",
      "Span [5]: \"one\"   [− Labels: CARDINAL (0.9939)] => 68:  Whether it's a one off case or whether we need to build enhance the feature around it\n",
      "Span [2]: \"one\"   [− Labels: CARDINAL (0.6394)] => 73:  And one other thing that is of interest is\n",
      "Span [17,18,19]: \"every two minutes\"   [− Labels: TIME (0.8656)] => 74:  We don't know why you're developing a type of pipeline and run it at every two minutes and things like that\n",
      "Span [7]: \"Al\"   [− Labels: PERSON (0.9041)] => 76:  Awesome, so that's what Al has been using to do all of his testing\n",
      "Span [7]: \"yesterday\"   [− Labels: DATE (0.7995)] => 78:  So the calls that we attended yesterday that's also rated around to this\n",
      "Span [3]: \"CVS\"   [− Labels: ORG (0.6789)] => 81:  Is that CVS pipeline is working\n",
      "Span [4,5,6]: \"the Blue Cross\"   [− Labels: ORG (0.7744)] => 82:  OK, and the Blue Cross one\n",
      "Span [15]: \"Johnny\"   [− Labels: PERSON (0.9987)] => 84:  OK, so we we've got a template and so we'll get Johnny up to speed by reviewing the CVS one\n",
      "Span [22]: \"CVS\"   [− Labels: ORG (0.8375)] => 84:  OK, so we we've got a template and so we'll get Johnny up to speed by reviewing the CVS one\n",
      "Span [9,10]: \"Blue Cross\"   [− Labels: ORG (0.6178)] => 85:  Or if we get another person is that Blue Cross they can then\n",
      "Span [13]: \"half\"   [− Labels: CARDINAL (0.5954)] => 86:  They can see everything flowing through framework and then cloning it and half of the initial work has already been done for them\n",
      "Span [8]: \"ALS\"   [− Labels: ORG (0.8642)] => 87:  Right and then in the meantime, ALS doing the discovery work on the next one because the discovery is really the hard part that the pipeline should be mechanical\n",
      "\n",
      "Cluster  5\n",
      "Span [5]: \"first\"   [− Labels: ORDINAL (0.8819)] => 11:  That's always the first thing, sure, so it\n",
      "Span [15]: \"Kyle\"   [− Labels: PERSON (0.9902)] => 23:  She's she has one power by guy that that was gonna work with Kyle\n",
      "Span [10]: \"Havel\"   [− Labels: PERSON (0.976)] => 30:  And then write it into the the dim person Havel\n",
      "Span [14]: \"10\"   [− Labels: CARDINAL (0.9828)] => 45:  Got it? And that very very quickly goes out and gets you 10 records\n",
      "Span [7]: \"2\"   [− Labels: CARDINAL (0.9771)] => 53:  I see OK and then Step 2\n",
      "Span [5,6]: \"Blue Cross\"   [− Labels: ORG (0.7055)] => 56:  \n",
      " \n",
      " For the other the Blue Cross person dimension and they can just look at the clone and see where it's different\n",
      "Span [3]: \"Alan\"   [− Labels: PERSON (0.9956)] => 62:  Yeah, Alan is very slow\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i+1)\n",
    "    display_entities(cluster)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea237d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnotesenv",
   "language": "python",
   "name": "mnotesenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

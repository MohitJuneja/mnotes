{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f119964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "# load model and tokenizer\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6674eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "\n",
    "# For managing audio file\n",
    "import librosa\n",
    "\n",
    "#Importing Pytorch\n",
    "import torch\n",
    "\n",
    "#Importing Wav2Vec\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a76da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb76ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(\"<<enter wave file here>>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a796ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio, rate = librosa.load(\"<<>>\", sr = 16000, duration=60, offset=59 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d95b2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01080456 -0.01366249 -0.00331523 ... -0.34110627 -0.15689012\n",
      " -0.04814944]\n"
     ]
    }
   ],
   "source": [
    "print(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f33b95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f59ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "C:\\Projects\\meetingnotes\\mnotesvenv\\lib\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py:423: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  FutureWarning,\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Importing Wav2Vec pretrained model\n",
    "\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "104c2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking an input value\n",
    "input_values = tokenizer(audio, return_tensors = \"pt\").input_values\n",
    "\n",
    "# Storing logits (non-normalized prediction values)\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# Storing predicted ids\n",
    "prediction = torch.argmax(logits, dim = -1)\n",
    "\n",
    "# Passing the prediction to the tokenzer decode to get the transcription\n",
    "transcription = tokenizer.batch_decode(prediction)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb50cfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O WHAT TOPICS THEY ARE RELATED TO SO YOU COULD SAY IN OUR CASE REALLY FOR GELASY WOULD BE ARE THEY TALKING ABOUT DET PAY DOWN SO THE DEGREE OF THAT OCCURRING IN THE TRANSGRIPTS OR ANOTHER FILINGS OR WHAT NOT BUT ALSO THE SENIMENT RELATED TO THAT SO WHAT IS ARE THEY TALKING ABOUT DET PAY DOWN IN A POSITIVE WAY OR A NEGATIVE WAY AND TO THAT PROVIDES A SIGNALS SO DETPAY DOWNCS MORE AN YOU DON'T THINK LIKE MINA IS LIKE OBVIOUSLY A ATOPIC IN TRANSCRIPTS SOMETIMES AYOU KNOW TAN'T GIVE IT AN POLICY YOURE SURE REPURCHASE POLICY BUT YOU KNOW I THINK YOUR POPY EVEN BETTER EXPERT THAN I AM ON ALL THE DIFFERENT TACHICATIORIES THAT WE BE INTERESTED IN EXPLORING  I THINK EMJE HAS LIKE KENIBUMS O MAYBE EM JE TO SHOW THE DIFFERENT AND WE WE KIND ABSOURCE THESE FROM THE SE AFE INSTITUTES LIKE THEY HAVE  MAY WE JUST PULPICS AY WHAT WE NE\n"
     ]
    }
   ],
   "source": [
    "# Printing the transcription\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3f9d29d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU KNOW THE  THE GENERAL OF WER BUT ONE'S CON O WORK BUT 'S MOSTALLY THE CHANGE ONE SO IF ANNALISTS BECOME MORE NEGATIVE THAN THAT'S PRETTY USEFUL OR I THINK THE EVEN THE S O ONE A A CHANGE OVER THE YEAR IS ALSO USEFUL AH AND TO DAY WERE WE BE INTERESTED IN TALKING TO IS THAT WE'RE WE'RE GETTING A A TOPIC MODERLY AND SO THAT IS WHERE WE'RE ACTUALLY TAGIN DIFFERENT SENTENCES IN THE TRANSCRIPT ON WH\n"
     ]
    }
   ],
   "source": [
    "# Printing the transcription\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1808cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') # Load the English Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aebcfdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = transcription\n",
    "doc = nlp(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fedce260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: O WHAT TOPICS THEY ARE RELATED TO SO YOU COULD SAY IN OUR CASE REALLY FOR GELASY WOULD BE ARE THEY TALKING ABOUT DET PAY DOWN SO\n",
      "1: THE DEGREE OF THAT OCCURRING IN THE TRANSGRIPTS OR ANOTHER FILINGS OR WHAT NOT BUT ALSO THE SENIMENT RELATED TO THAT SO WHAT IS ARE THEY TALKING ABOUT DET PAY DOWN IN A POSITIVE WAY OR A NEGATIVE WAY AND TO THAT PROVIDES A SIGNALS SO DETPAY DOWNCS MORE\n",
      "2: AN YOU DON'T THINK LIKE MINA IS LIKE OBVIOUSLY\n",
      "3: A ATOPIC IN TRANSCRIPTS\n",
      "4: SOMETIMES AYOU KNOW TAN'T GIVE IT AN POLICY YOURE SURE REPURCHASE POLICY\n",
      "5: BUT YOU KNOW\n",
      "6: I THINK YOUR POPY EVEN BETTER EXPERT THAN I AM ON ALL THE DIFFERENT TACHICATIORIES THAT WE BE INTERESTED IN EXPLORING  I THINK EMJE HAS LIKE KENIBUMS O\n",
      "7: MAYBE EM JE TO SHOW THE DIFFERENT AND WE\n",
      "8: WE KIND ABSOURCE THESE FROM THE SE AFE INSTITUTES\n",
      "9: LIKE THEY HAVE  MAY WE JUST PULPICS AY WHAT WE NE\n"
     ]
    }
   ],
   "source": [
    "for idx,sent in enumerate(doc.sents):\n",
    "    print(f\"{idx}: {sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to read in sound file\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "# load dummy dataset and read soundfiles\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "# tokenize\n",
    "input_values = processor(ds[\"speech\"][:2], return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
    "\n",
    "# retrieve logits\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnotesenv",
   "language": "python",
   "name": "mnotesenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

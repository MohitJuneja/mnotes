{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3a2d11",
   "metadata": {},
   "source": [
    "# This notebook get the clusters results and apply insights to find the contradicting groups within each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fadfec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909a8973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3fde98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CONTRADICTION': 0, 'NEUTRAL': 1, 'ENTAILMENT': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e95053b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1194,  0.4705, -0.4956]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"I like you. </s></s> I love you.\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0) # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c580e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2865, 0.5168, 0.1967]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96792e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = ['\\nGot something else? Data classification stuff for data inventory', 'Uhm? Just telling telling data catalog', \"I've been messing around with databases\", 'Sure, trying to do data classification stuff for data for SB 475, sure', \"Understood, so that's why that's more for the data governance data inventory you're trying to do\", \"They'll ask For more information anyways, regardless of how much information you provide them\", \"Well and and the other thing I'm working on, if I can work it out might make it a moot point as far as your studio, I don't know because I've been pushing and trying since I've been playing with this to try and stitch together ER studio with the other stuff because a lot of our metadata is in the data models so\", \"You know the databases don't have anything\", 'Writing out SQL out of the data model, extended properties and putting them in the database', \"In order to put the metadata in the database, that's what, then and then\", 'I then I applied it to talent from the database and it does', \"Sure, but does it work for actually do it? How is the coverage though? Like when you're when you are writing the sequel out of the data model and the extended extended properties are in the database, is there a way that you can see the coverage? Like, is that a reflective of 90% of what was in your studio, or less or more? To have a good feel about the coverage\", \"I'm not sure what you mean, are you? If you're asking how many databases have models, you know, yeah, I mean that they missed\", 'There must be a gap between the extended attributes within the database, the actual physical databases as we have and what we have in ER studio, right? So one way was to connect Talent data catalog to ER studio and then have those extended properties show up for', \"Because data catalog can read the databases as is 'cause the tables would match and databases would match\", \"The problem that was there, which was a gap between ER studio and talent and the database is you may have already resolved that, but how much have you resolved it like from a coverage standpoint, is it looking as good as near 100% coverage or is it like 50% and then we have to do some manual stuff on top of it? Uhm? I still don't exactly understand the question\", \"I have created extended properties for the with the descriptions with the with the table definitions, so they're showing up here in the business description\", \"And then there's also extended properties for the sensitivity classification, and they're coming in here, but\", \"So I have two attributes named sensitive, so I'm trying to figure out how effectively to actually work with it\", \"I think we have a call with Cornelius as well and we can have somebody who's expert in data catalog give us a session with all these questions they can answer it for us, but my question was thank you for sharing this\", 'So my question was this table is trust ESX trust', 'And you have this, you know, with these columns listed and then you have extended attributes like business, description, comment, sensitivity', \"That's going to be useful for data classification\", \"I mean, all this comes from the data models, so at this point in time I'm the only person doing data models with that\", \"Has any classifications in the data models at all, so we'd have all that work to do to like\", \"The thought that we shouldn't actually be classifying the data we want the business to classify the data, so it might go the other way around where we add the custom attributes and set them to blank and then turn this over the business and let them and create a worksheet out of this\", \"There's ways you can take all this data and put it into a worksheet for for the\", 'For the end users, yes, and let them go through and mark the classifications and then exported out here and it and import it into the database or into the model and then back into the database or something so', 'At the end of the day, if we can get all this stuff into the database, yes', \"Talent Data catalog does a much better job of stitching things together between the ETL's and the pipelines and everything else, yes\", 'And the databases that it does to ER studio', 'We can we have a call with Cornelius like the talent you know, customer support manager and we can bring this up as one of the use cases for getting data catalog person', 'To solve some of these problems for us, and they may also educate us about other features for automatic classification', 'They have a feature of auto classification where they look at maybe a 10,000 data points in each attribute in each column and then decide whether it is a PCI or HIPAA or some kind of a related column', \"The data and then kind of stamp that tag that value and that's all very user friendly and people can change it if they want to\", 'But it may be a hybrid approach where talent data catalog does some of it automatically', 'Some of it you can prime the data and then business users can take care of the rest', 'I was intent on trying to make ER studio Stitch ER studio in and try and use it as the glossary and stuff and', 'Totally, I think none of us is an expert in this version of catalog', \"Extended properties mean you know, looking at it, 'cause otherwise\", 'Yeah, and actually I did this extended property wrong on that one column', 'You give SQL Server and and it gives different label IDs and and stuff and and they sent the extended properties supposed to be based on that label ID and label name']\n",
    "test_cluster  = [\"And some of that we've completed working with strategic\", \"I'll incorporate that feedback into the notes and how we structure this effort going forward\", 'I see that I and IMD, which I think is a great idea', \"It's great that we've been pushing them to do that, and they're gonna take it on\", 'You know only and only applicable to IMD', 'We may use some of those best practices overall for the all the other line of business is we may not', \"Like so could cash or be a little bit more like let's say a mouthon, you know\", \"In this case, yes, but almost even solutions architecture, right and? Uhm, you know? That's what we want, yes? And you know\", \"You know, we can't beg people\", \"You know all the time to adopt our recommendations, yes, but that doesn't stop us from making the best recommendations that are in the best interests of the organization\", 'It is about you know, establishing what the architects are bringing to the table', 'You know solution should look like', 'Not on our team', 'That means recognizing that yes, yes', 'The foremost priority you know these', 'Sure, other than that, just trying to keep keep the To Do List', 'You know how you guys are looking at the priorities and now we are looking at the priorities', \"I'll concise it from an executive perspective from that lens where there are four or five bullet points which reflects most of the stuff\", 'And yeah, and then maybe we will bury the details in appendix or somewhere if somebody is interested we can dig down and give more color', \"Wyndham Chat a little bit about merit, 'cause I know we talked about this and so we started looking at merit and across the board\", 'Sure, and, but there are some parameters and one of the parameters is we can only go so high on percentage', \"Uh, without having to go through approval all the way to the top all the way to the top, and then it's fine\", \"We can do that, but as an alternative, what we're really thinking about doing is is a one time merit, almost like a bonus\", \"Sure, he submitted it in 2 E and and so it's not none of the merits\", 'A little bit, you know, between there and in 10K and well what I like about this idea is', \"It gives us still an opportunity to do something else later because one of the aspects we were up against with you is you're starting to bump up against your limit and your position right grade, right, and so we're still gonna\", \"We're leaving a little bit of a limit there that we can play with\", \"We're happy to do it so you deserve it and just so you know I don't always get kind of the final word on merit it just it just hits the payroll\", \"So from overall I have project perspective and if you wanna like very quick update I can splice it people perspective or people wise or can slice it projectwise what's your preference of kind of when you hear updates? Give me, give me some people slice OK\", 'You know in between primary and secondary', 'That project may speed up a lot', \"We're taking some good steps in that direction\", 'Some information as you guys are thinking about that, we might have to talk about it more', 'A little frustrated with the amount of patience it needs to get things rolling here and to for other functional areas to understand our point of view like architecture, point of view', \"But we're making some small wins with a little bit of flexibility\", \"We don't want to be too flexible either, but we need to\", 'We need to achieve our first win', \"Like a first win that we can showcase, and if it's not list data OPS\", 'But we will kind of', '\\n\\nThere may be a little curved line to get there to lose the battles for sandboxes prove that they were wrong in the sandboxes', \"The first plate thing to do, yes, rather than what your team is doing when they're kind of associating their security model to how they manage the S drive\", 'But I also want to speak their point of view', 'You know where we need to be in terms of aligning, aligning with their thought processes so right', 'Yes, yes that is exactly team aware', \"Exactly you know what what constraints you're currently working on exactly, and by the way\", \"If if, let's say, Kushner could take on some of those stories for you, right? Let cash or help you solve this problem\", 'Yes, yes, totally and turn it into a positive, you know', 'So people are working furiously to to kind of get the right', '\\n\\nInadi with group ID', 'You know, I, I think we can get all the support we need for that', 'Just you know let us know what we need', 'If we can get it in a move, like if we can add some speed to it velocity to it', \"\\n\\nMutan wasn't leaving a lot of other things were I wasn't doing so we need to have a fresh assessment of how much I can work on that project with everything else\", \"And if that impacts beyond the threshold of a dry and wants to see, we will, definitely, I'll put a case together for getting a contract with somebody who can get the same velocity as they would like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04706219",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1=test_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7af5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"And some of that we've completed working with strategic </s></s> I see that I and IMD, which I think is a great idea\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster1[0] + \" </s></s> \" + cluster1[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdfb5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(cluster1[0] + \" </s></s> \" + cluster1[2], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52e5ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CONTRADICTION': 0, 'NEUTRAL': 1, 'ENTAILMENT': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2153de26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0698, 0.9209, 0.0092]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([1]).unsqueeze(0) # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "torch.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc84323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0328\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac4d002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: semantic search\n",
    "\n",
    "We have a corpus with various sentences. Then, for a given query sentence,\n",
    "we want to find the most similar sentence in this corpus.\n",
    "\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2281951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: I would like to complete this action\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "I'll incorporate that feedback into the notes and how we structure this effort going forward (Score: 0.3214)\n",
      "We need to achieve our first win (Score: 0.2896)\n",
      "If we can get it in a move, like if we can add some speed to it velocity to it (Score: 0.2635)\n",
      "The foremost priority you know these (Score: 0.2376)\n",
      "And yeah, and then maybe we will bury the details in appendix or somewhere if somebody is interested we can dig down and give more color (Score: 0.2369)\n",
      "We're taking some good steps in that direction (Score: 0.2329)\n",
      "Uh, without having to go through approval all the way to the top all the way to the top, and then it's fine (Score: 0.2328)\n",
      "Just you know let us know what we need (Score: 0.2305)\n",
      "You know solution should look like (Score: 0.2130)\n",
      "And some of that we've completed working with strategic (Score: 0.2107)\n",
      "Sure, other than that, just trying to keep keep the To Do List (Score: 0.1913)\n",
      "It's great that we've been pushing them to do that, and they're gonna take it on (Score: 0.1854)\n",
      "Like a first win that we can showcase, and if it's not list data OPS (Score: 0.1845)\n",
      "But we will kind of (Score: 0.1824)\n",
      "\n",
      "\n",
      "Inadi with group ID (Score: 0.1794)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: I'll incorporate a specific task or item\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Sure, other than that, just trying to keep keep the To Do List (Score: 0.5195)\n",
      "I'll incorporate that feedback into the notes and how we structure this effort going forward (Score: 0.5195)\n",
      "So from overall I have project perspective and if you wanna like very quick update I can splice it people perspective or people wise or can slice it projectwise what's your preference of kind of when you hear updates? Give me, give me some people slice OK (Score: 0.3677)\n",
      "Exactly you know what what constraints you're currently working on exactly, and by the way (Score: 0.3525)\n",
      "Like a first win that we can showcase, and if it's not list data OPS (Score: 0.3436)\n",
      "The foremost priority you know these (Score: 0.3388)\n",
      "Just you know let us know what we need (Score: 0.3365)\n",
      "And some of that we've completed working with strategic (Score: 0.3192)\n",
      "And yeah, and then maybe we will bury the details in appendix or somewhere if somebody is interested we can dig down and give more color (Score: 0.3110)\n",
      "If we can get it in a move, like if we can add some speed to it velocity to it (Score: 0.3065)\n",
      "That project may speed up a lot (Score: 0.2977)\n",
      "A little bit, you know, between there and in 10K and well what I like about this idea is (Score: 0.2921)\n",
      "We can do that, but as an alternative, what we're really thinking about doing is is a one time merit, almost like a bonus (Score: 0.2865)\n",
      "We may use some of those best practices overall for the all the other line of business is we may not (Score: 0.2773)\n",
      "In this case, yes, but almost even solutions architecture, right and? Uhm, you know? That's what we want, yes? And you know (Score: 0.2718)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Corpus with example sentences\n",
    "corpus = cluster1\n",
    "\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = [\"I would like to complete this action\", \"I'll incorporate a specific task or item\"]\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(15, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores[:], k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "\n",
    "    \"\"\"\n",
    "    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c3b175d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2107,  0.3214,  0.0581,  0.1854,  0.0551,  0.0988,  0.0318,  0.0390,\n",
      "         0.1770, -0.0490,  0.1551,  0.2130,  0.0129,  0.1194,  0.2376,  0.1913,\n",
      "         0.0849,  0.1058,  0.2369,  0.0589,  0.0590,  0.2328,  0.1552,  0.1132,\n",
      "         0.0777,  0.1506,  0.0792,  0.0922,  0.1419,  0.1054,  0.1398,  0.2329,\n",
      "         0.1214,  0.0763, -0.0104,  0.0901,  0.2896,  0.1845,  0.1824,  0.0024,\n",
      "         0.0340,  0.1453,  0.0394,  0.0540,  0.0748,  0.1122,  0.0483,  0.1443,\n",
      "         0.1794,  0.1753,  0.2305,  0.2635,  0.0979,  0.0947], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "topk = 5\n",
    "\n",
    "query = \"I would like to complete this action\"\n",
    "query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores[1:], k=top_k)\n",
    "print(cos_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c164600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.3214, 0.2896, 0.2635, 0.2376, 0.2369, 0.2329, 0.2328, 0.2305, 0.2130,\n",
       "        0.1913, 0.1854, 0.1845, 0.1824, 0.1794, 0.1770], device='cuda:0'),\n",
       "indices=tensor([ 0, 35, 50, 13, 17, 30, 20, 49, 10, 14,  2, 36, 37, 47,  7],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3eb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnotesenv",
   "language": "python",
   "name": "mnotesenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
